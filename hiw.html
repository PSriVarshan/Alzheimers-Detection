<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>How It Works - AlzWELL</title>
    <link rel="stylesheet" href="static/styles/styles.css">
    <style>
        h2,h3 {
            color: black;
        }
    </style>
</head>
<body>
    <div class="background-image"></div>

    <nav>
        <div class="logo">AlzWELL</div>
        <ul>
            <li><a href="home.html">Home</a></li>
            <li><a href="about.html">About</a></li>
            <li><a href="ed.html">Early Detection</a></li>
            <li><a href="hiw.html" class="active">How It Works</a></li>
            <li><a href="res.html">Resources</a></li>
            <li><a href="faqs.html">FAQs</a></li>
            <li><a href="index.html">Logout</a></li>
        </ul>
    </nav>

    <header>
        <h4>How It Works</h4>
    </header>

    <div class="container">
        <!-- Introduction -->
        <section class="card">
            <h2>Understanding Our Alzheimer's Detection System</h2>
            <p>
                AlzWELL integrates multiple advanced techniques to predict and analyze Alzheimer's Disease using MRI data and biomarker analysis. Here's a comprehensive guide on how our system works:
            </p>
        </section>
        <br>

        <!-- MRI Section -->
        <section class="card">
            <h2>Understanding Our MRI-Based Alzheimer's Detection</h2>
            <p>
                Our MRI-based model utilizes deep learning to detect Alzheimer's Disease with high accuracy. By leveraging MRI scans in DICOM (.dcm) format, the model processes the images to predict the likelihood of Alzheimer's. Here's an in-depth breakdown of how the model works:
            </p>
        </section>
        <br>

        <!-- Input Section -->
        <section class="card">
            <h2>Step 1: Input - DICOM to Image Conversion</h2>
            <p>
                MRI scans are typically stored in the DICOM (.dcm) format, which contains both image data and metadata. To prepare these scans for analysis:
            </p>
            <ul>
                <li><strong>Image Extraction:</strong> The pixel data is extracted from DICOM files and converted to commonly used image formats like PNG or JPEG.</li>
                <li><strong>Preprocessing:</strong> The images are resized to a uniform dimension (e.g., 32x32x3), normalized to a [0,1] scale, and augmented if necessary to enhance the training data.</li>
                <li><strong>Color Encoding:</strong> While MRIs are grayscale, the images are converted into a format compatible with deep learning frameworks.</li>
            </ul>
            <p>
                This preprocessing ensures consistency and compatibility with the model architecture.
            </p>
        </section>
        <br>

        <!-- Model Architecture -->
        <section class="card">
            <h2>Step 2: Model Architecture</h2>
            <p>
                The deep learning model follows a Convolutional Neural Network (CNN) architecture optimized for image classification tasks. Here is a detailed walkthrough of the layers:
            </p>
            <h3>1. Convolutional Layers</h3>
            <ul>
                <li>
                    <strong>Conv2D Layer 1:</strong>
                    - Input: (32x32x3) images.<br>
                    - Function: Extracts features like edges and textures using 32 filters of size (3x3).<br>
                    - Output: (16x16x32) feature map (downsampled by a factor of 2 using strides).
                </li>
                <li>
                    <strong>Conv2D Layer 2:</strong>
                    - Input: Downsampled feature maps from Layer 1.<br>
                    - Function: Detects more complex patterns using 64 filters of size (3x3).<br>
                    - Output: (8x8x64) feature map.
                </li>
                <li>
                    <strong>Conv2D Layer 3:</strong>
                    - Input: Intermediate feature maps.<br>
                    - Function: Captures highly abstract patterns with 128 filters of size (3x3).<br>
                    - Output: (2x2x128) feature map.
                </li>
            </ul>

            <h3>2. Pooling Layers</h3>
            <ul>
                <li>
                    <strong>MaxPooling2D:</strong> Applied after each convolutional layer to reduce the spatial dimensions while retaining the most significant features.
                </li>
            </ul>

            <h3>3. Fully Connected Layers</h3>
            <ul>
                <li>
                    <strong>Dense Layer 1:</strong>
                    - Input: Flattened feature map (128 units).<br>
                    - Function: Processes extracted features and learns non-linear combinations.<br>
                    - Output: 1024 neurons.
                </li>
                <li>
                    <strong>Dropout:</strong> Regularization technique to prevent overfitting (drop rate = 0.5).
                </li>
                <li>
                    <strong>Dense Layer 2:</strong>
                    - Function: Final classification layer predicting 4 categories (e.g., normal, mild cognitive impairment, moderate AD, severe AD).<br>
                    - Output: 4 neurons (softmax activation for probabilities).
                </li>
            </ul>
            <img src="Archi[1].png" alt="Model Architecture" class="image-centered">
        </section>
        <br>

        <!-- Prediction -->
        <section class="card">
            <h2>Step 3: Prediction and Interpretation</h2>
            <p>
                After the model processes the input:
            </p>
            <ul>
                <li>
                    <strong>Prediction:</strong> The model outputs a probability distribution across 4 categories (e.g., Normal, Mild Cognitive Impairment, Moderate AD, Severe AD).
                </li>
                <li>
                    <strong>Visualization:</strong> Heatmaps and activation maps can be generated to interpret the features contributing to the classification.
                </li>
                <li>
                    <strong>Integration:</strong> The predictions are integrated into the platform to provide comprehensive reports for clinicians and researchers.
                </li>
            </ul>
        </section>
        <br>

        <!-- Conclusion -->
        <section class="card">
            <h2>Why This Model Works</h2>
            <p>
                The deep learning model is designed to detect subtle patterns in MRI scans that are often imperceptible to the human eye. By combining robust preprocessing, an optimized CNN architecture, and thorough validation, the model provides a reliable tool for early Alzheimer's detection. This innovative approach empowers clinicians with AI-driven insights for better decision-making.
            </p>
        </section>
        <br>

        <!-- Biomarker Analysis Section -->
        <section class="card">
            <h2>Step 2: Biomarker Analysis</h2>
            <p>
                Biomarker analysis combines patient metadata and laboratory values to predict Alzheimer's likelihood. The system uses ensemble learning with a stacking approach to combine predictions from multiple models. Here's how it works:
            </p>

            <h3>Input Features</h3>
            <ul>
                <li><strong>Age:</strong> Numeric value indicating the patient's age.</li>
                <li><strong>Gender:</strong> Selected from a dropdown (Male, Female).</li>
                <li><strong>FDG Value:</strong> Numeric input representing fluorodeoxyglucose (FDG) uptake.</li>
                <li><strong>PIB Value:</strong> Numeric input indicating Pittsburgh compound B (PIB) tracer value.</li>
                <li>
                    <strong>Marital Status:</strong> Dropdown with options:
                    <ul>
                        <li>Married</li>
                        <li>Divorced</li>
                        <li>Widowed</li>
                        <li>Unmarried</li>
                        <li>Unknown</li>
                    </ul>
                </li>
                <li><strong>APOE4 Allele Count:</strong> Numeric count of APOE4 alleles (0, 1, or 2).</li>
            </ul>

            <h3>Model Workflow</h3>
            <p>The system employs a stacking ensemble learning approach, combining the predictions of three base learners:</p>
            <ul>
                <li>
                    <strong>Random Forest Classifier:</strong> Uses multiple decision trees to capture non-linear relationships and reduce overfitting.
                </li>
                <li>
                    <strong>Gradient Boosting Classifier:</strong> Focuses on minimizing error by iteratively training weak models to improve performance.
                </li>
                <li>
                    <strong>Support Vector Machine (SVM):</strong> Employs a linear kernel and probability estimates to maximize classification margins.
                </li>
            </ul>
            <p>The predictions from these base learners are combined by a meta-learner (typically a logistic regression model) to generate the final prediction.</p>

            <h3>Stacking Code Overview</h3>
            <pre>
# Define base learners
base_learners = [
    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),
    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),
    ('svm', SVC(kernel='linear', probability=True))
]

# Define stacking classifier
stacking_model = StackingClassifier(
    estimators=base_learners,
    final_estimator=LogisticRegression(),
    cv=5
)

# Train and predict
stacking_model.fit(X_train, y_train)
predictions = stacking_model.predict(X_test)
            </pre>

            <h3>Prediction Output</h3>
            <p>
                The stacking model outputs a probability distribution indicating the likelihood of Alzheimer's presence or progression. These predictions are displayed in user-friendly visualizations, providing actionable insights for clinicians and researchers.
            </p>
        </section>
        <br>

        <!-- Final Section -->
        <section class="card">
            <h2>Conclusion</h2>
            <p>
                AlzWELL’s system combines state-of-the-art deep learning and ensemble learning techniques to deliver precise and reliable Alzheimer's predictions. Whether through MRI analysis or biomarker-based predictions, our platform empowers early detection and informed decision-making.
            </p>
        </section>
    </div>
</body>
</html>
